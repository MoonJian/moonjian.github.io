<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>(Paper-Reading) A Comprehensive Analysis of Deep Regression</title>
    <link href="/2022/04/04/Survey-Deep-Regression/"/>
    <url>/2022/04/04/Survey-Deep-Regression/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul><li>Regression could also be formulated as classification, why should we dig into this topic?<blockquote><p>First, there is an inherent trade-off between the complexity of the optimization problem and the accuracy of the method due to the discretization process. Second, in absence of a specific formulation, a confusion between two classes has the same cost independently of the corresponding error in the target space. Last, the discretization method that is employed must be designed specifically for each task, and therefore general-purpose methodologies must be used with care. Thus, we should have a generic vanilla deep regression.</p></blockquote></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>(Paper Reading) Future Research Directions on Domain Generalization</title>
    <link href="/2022/01/05/PR-Domain-Generalization-Future-Directions/"/>
    <url>/2022/01/05/PR-Domain-Generalization-Future-Directions/</url>
    
    <content type="html"><![CDATA[<p>æœ€è¿‘åœ¨ç ”ç©¶é¢†åŸŸæ³›åŒ–ï¼Œæƒ³æ‰¾ä¸ªæ–¹å‘åšç‚¹ä¸œè¥¿ï¼Œäºæ˜¯æ•´ç†äº†æœ€è¿‘çœ‹çš„ä¸€ç¯‡ç»¼è¿°<em>Domain Generalization in Vision: A Survey</em><sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="Domain Generalization in Vision: A Survey">[1]</span></a></sup>ï¼Œå¸Œæœ›èƒ½ä»ä¸­æœ‰æ‰€æ”¶è·ã€‚</p><h1 id="å‘å±•æ–¹å‘"><a href="#å‘å±•æ–¹å‘" class="headerlink" title="å‘å±•æ–¹å‘"></a>å‘å±•æ–¹å‘</h1><p>ä½œè€…ä»ä¸‰ä¸ªæ–¹é¢è¿›è¡Œäº†æ€»ç»“ï¼š<strong>æ¨¡å‹ç»“æ„</strong>ã€<strong>å­¦ä¹ æ–¹æ³•</strong>å’Œ<strong>è¯„ä»·åŸºå‡†ï¼ˆBenchmarkï¼‰</strong>ã€‚</p><h2 id="æ¨¡å‹ç»“æ„"><a href="#æ¨¡å‹ç»“æ„" class="headerlink" title="æ¨¡å‹ç»“æ„"></a>æ¨¡å‹ç»“æ„</h2><h3 id="åŠ¨æ€ç»“æ„ï¼ˆDynamic-Architecturesï¼‰"><a href="#åŠ¨æ€ç»“æ„ï¼ˆDynamic-Architecturesï¼‰" class="headerlink" title="åŠ¨æ€ç»“æ„ï¼ˆDynamic Architecturesï¼‰"></a>åŠ¨æ€ç»“æ„ï¼ˆDynamic Architecturesï¼‰</h3><p>åœ¨æºåŸŸè®­ç»ƒå¥½åï¼Œç¥ç»ç½‘ç»œçš„å‚æ•°é€šå¸¸å°±å›ºå®šäº†ä¸‹æ¥ï¼Œå……å½“ä¸€ä¸ªç‰¹å¾æå–å™¨ï¼Œç›´æ¥åº”ç”¨åœ¨ç›®æ ‡åŸŸä¸­ã€‚ä½†æ˜¯ç›®æ ‡åŸŸçš„æ•°æ®åˆ†å¸ƒå¯èƒ½ä¼šå’ŒæºåŸŸå·®å¼‚å¾ˆå¤§ï¼Œå‚æ•°å›ºå®šçš„ç‰¹å¾æå–å™¨å¯èƒ½æå–ä¸åˆ°æœ‰æ•ˆçš„ç‰¹å¾ã€‚é’ˆå¯¹è¿™ä¸ªé—®é¢˜ï¼Œä¸€ç§å¯èƒ½çš„è§£å†³æ€è·¯æ˜¯æ„å»ºåŠ¨æ€ç¥ç»ç½‘ç»œï¼ˆDynamical Neural Networksï¼‰ï¼Œè®©ç½‘ç»œçš„ç»“æ„å’Œæƒé‡ä¸è¾“å…¥æ•°æ®æŒ‚é’©ã€‚</p><blockquote><p>è¿™æ˜¯æˆ‘å¾ˆæ„Ÿå…´è¶£çš„ä¸€ä¸ªæ–¹å‘ï¼Œè®©åŠ¨æ€å˜åŒ–çš„ç½‘ç»œç»“æ„å¤„ç†åŠ¨æ€å˜åŒ–çš„æ•°æ®åˆ†å¸ƒã€‚åœ¨é¢†åŸŸæ³›åŒ–é—®é¢˜ä¸­ï¼Œå°±æ˜¯å¤„ç†é¢†åŸŸçš„å˜åŒ–ï¼Œ Domain Shiftï¼Œæ›´è¿›ä¸€æ­¥ï¼Œç”šè‡³å¯ä»¥ç”¨äºå¤„ç†æŒç»­é¢†åŸŸæ³›åŒ–ï¼ˆContinuous Domain Generalizationï¼‰é—®é¢˜ã€‚ä½†éš¾ç‚¹åœ¨äºï¼š1. é€‰ç”¨æ€æ ·çš„åŠ¨æ€ç½‘ç»œç»“æ„ï¼Ÿ2. å¦‚ä½•å¤„ç†é¢†åŸŸæ³›åŒ–ç›®æ ‡åŸŸä¸­çš„æ— æ ‡è®°æ•°æ®ï¼Ÿ3. å¦‚ä½•åˆ©ç”¨æ— æ ‡è®°æ•°æ®åŠ¨æ€æ”¹å˜ç½‘ç»œç»“æ„ï¼Ÿ4. æ˜¯ç½‘ç»œç»“æ„æ•´ä½“åŠ¨æ€å˜åŒ–è¿˜æ˜¯éƒ¨åˆ†åŠ¨æ€å˜åŒ–ï¼Ÿ</p></blockquote><h3 id="è‡ªé€‚åº”å½’ä¸€åŒ–å±‚ï¼ˆAdaptive-Normalization-Layersï¼‰"><a href="#è‡ªé€‚åº”å½’ä¸€åŒ–å±‚ï¼ˆAdaptive-Normalization-Layersï¼‰" class="headerlink" title="è‡ªé€‚åº”å½’ä¸€åŒ–å±‚ï¼ˆAdaptive Normalization Layersï¼‰"></a>è‡ªé€‚åº”å½’ä¸€åŒ–å±‚ï¼ˆAdaptive Normalization Layersï¼‰</h3><p>è‡ªé€‚åº”å½’ä¸€åŒ–å±‚åŠ¨æ€æ”¹å˜ç½‘ç»œæƒé‡ï¼ˆå‡†ç¡®åœ°è¯´ï¼Œæ˜¯CNNä¸­BNå±‚çš„æƒé‡ï¼‰ï¼Œä¸æ”¹å˜ç½‘ç»œç»“æ„ã€‚ç¥ç»ç½‘ç»œBNå±‚å¯ä»¥è¡¨ç¤ºä¸ºï¼š</p><script type="math/tex; mode=display">y = \gamma \frac{x-\mu}{\delta} + \beta</script><p>å…¶ä¸­ï¼Œ$(\gamma,\beta)$æ˜¯å¯å­¦ä¹ çš„å‚æ•°ï¼Œ$(\mu,\delta)$æ˜¯è®­ç»ƒé›†ä¸Šçš„ç§»åŠ¨å¹³å‡å’Œç§»åŠ¨æ ‡å‡†å·®ï¼Œè¿™äº›å‚æ•°éƒ½å’Œè®­ç»ƒæ•°æ®çš„åˆ†å¸ƒæœ‰å…³ã€‚å¦‚ä½•è®©å½’ä¸€åŒ–å±‚çš„å‚æ•°è‡ªé€‚åº”ç›®æ ‡åŸŸä¸­çš„æ•°æ®åˆ†å¸ƒï¼Œæ˜¯ä¸€ä¸ªå¯èƒ½çš„æ–¹å‘ã€‚</p><blockquote><p>ç›¸æ¯”åŠ¨æ€ç»“æ„æ–¹æ³•ï¼Œè‡ªé€‚åº”å½’ä¸€åŒ–å±‚æ–¹æ³•æ›´åŠ ç®€æ´ï¼Œä½†æ˜¯ç›®å‰å·²æœ‰ä¸€ç¯‡ç›¸å…³çš„å·¥ä½œäº†<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="Tent: Fully Test-Time Adaptation by Entropy Minimization">[2]</span></a></sup></p></blockquote><h2 id="å­¦ä¹ æ–¹æ³•"><a href="#å­¦ä¹ æ–¹æ³•" class="headerlink" title="å­¦ä¹ æ–¹æ³•"></a>å­¦ä¹ æ–¹æ³•</h2><p>è¿™ä¸€éƒ¨åˆ†å¯ä»¥æŒ–çš„å‘æ˜¯æœ€å¤šçš„ï¼Œå½“ç„¶ï¼Œä¹Ÿæ˜¯æœ€å·çš„ï¼ˆç¬‘~</p><h3 id="æ— é¢†åŸŸæ ‡ç­¾å­¦ä¹ ï¼ˆLearning-without-Domain-Labelsï¼‰"><a href="#æ— é¢†åŸŸæ ‡ç­¾å­¦ä¹ ï¼ˆLearning-without-Domain-Labelsï¼‰" class="headerlink" title="æ— é¢†åŸŸæ ‡ç­¾å­¦ä¹ ï¼ˆLearning without Domain Labelsï¼‰"></a>æ— é¢†åŸŸæ ‡ç­¾å­¦ä¹ ï¼ˆLearning without Domain Labelsï¼‰</h3><p>å½“å‰çš„å¤§å¤šæ•°é¢†åŸŸæ³›åŒ–æ–¹æ³•åœ¨è®­ç»ƒæ—¶éœ€è¦çŸ¥é“ä¸åŒåŸŸçš„é¢†åŸŸæ ‡ç­¾ï¼Œå³åŸŸæ˜¯äº‹å…ˆåˆ’åˆ†å¥½çš„ï¼ŒåŸŸä¸åŸŸä¹‹é—´çš„ç•Œé™å¾ˆæ˜ç¡®ã€‚ä½†æ˜¯åœ¨ç°å®åœºæ™¯ä¸­ï¼ŒåŸŸçš„æ ‡ç­¾æ˜¯å¾ˆéš¾è·å¾—å’Œå®šä¹‰çš„ã€‚è¿™ä¸ªæ—¶å€™ï¼Œè™½ç„¶æˆ‘ä»¬æœ‰å¾ˆå¤šæ ‡è®°å¥½çš„æ•°æ®ï¼Œä½†æ˜¯å´ä¸çŸ¥é“è¿™äº›æ•°æ®å¯ä»¥è¢«åˆ’åˆ†åˆ°å“ªäº›åŸŸä¸­ã€‚åœ¨è¿™ç§è®¾å®šä¸‹ï¼Œå½“å‰çš„SOTAæ–¹æ³•å¾ˆéš¾ç›´æ¥åº”ç”¨ã€‚è™½ç„¶ç›®å‰å·²æœ‰äº†ä¸€äº›å·¥ä½œï¼Œä½†æ˜¯ä»ä¸å°½å¦‚äººæ„ã€‚</p><blockquote><p>ä¸€å¼€å§‹æˆ‘å¹¶ä¸å¾ˆæ¸…æ¥šè¿™ä¸ªè®¾å®šæ˜¯å¦æœ‰æ„ä¹‰ï¼Œå› ä¸ºè¿™ç›¸å½“äºlearning in the wildï¼ˆè™½ç„¶æœ‰æ ‡ç­¾ï¼Œä½†æ²¡æœ‰åŸŸä¿¡æ¯ï¼‰ï¼Œå¦‚ä½•å®šä¹‰Target Domainï¼Ÿå¯èƒ½éœ€è¦å†çœ‹ä¸‹ç»¼è¿°ä¸­æåˆ°çš„å‡ ç¯‡è®ºæ–‡ã€‚</p></blockquote><h3 id="æ–°åŸŸæ•°æ®ç”Ÿæˆï¼ˆLearning-to-Synthesize-Novel-Domainsï¼‰"><a href="#æ–°åŸŸæ•°æ®ç”Ÿæˆï¼ˆLearning-to-Synthesize-Novel-Domainsï¼‰" class="headerlink" title="æ–°åŸŸæ•°æ®ç”Ÿæˆï¼ˆLearning to Synthesize Novel Domainsï¼‰"></a>æ–°åŸŸæ•°æ®ç”Ÿæˆï¼ˆLearning to Synthesize Novel Domainsï¼‰</h3><p>ä¸Out-of-distribution(OOD) Generalizationç›¸å…³çš„ç ”ç©¶<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks">[3]</span></a></sup>è¡¨æ˜ï¼Œå¢åŠ åŸŸçš„å¤šæ ·æ€§æœ‰åˆ©äºæé«˜OODæ£€æµ‹çš„æ³›åŒ–æ€§ã€‚ä½†æ˜¯ï¼ŒåŸŸæ˜¯æ— ç©·æ— å°½çš„ï¼Œä¸å¯èƒ½æ”¶é›†åˆ°æ‰€æœ‰çš„åŸŸæ•°æ®ã€‚å› æ­¤ï¼Œå­¦ä¼šå¦‚ä½•ç”Ÿæˆæ–°åŸŸæ•°æ®æ˜¯ä¸€ä¸ªå¯èƒ½çš„æ–¹å‘ã€‚</p><blockquote><p>è¿™ä¸ªæ–¹å‘å·²ç»æœ‰ä¸å°‘å·¥ä½œäº†ï¼Œä½†æ˜¯é—®é¢˜çš„å®è´¨å¹¶æ²¡æœ‰å¾—åˆ°è§£å†³ï¼Œä¾é å¢åŠ è®­ç»ƒé›†çš„å¤šæ ·æ€§æ¥æé«˜æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨æˆ‘çœ‹æ¥ï¼Œæˆæœ¬è¿˜æ˜¯å¤ªé«˜ï¼Œnot my taste~</p></blockquote><h3 id="é¿å…å­¦ä¹ æ·å¾„ï¼ˆAvoiding-Learning-Shortcutï¼‰"><a href="#é¿å…å­¦ä¹ æ·å¾„ï¼ˆAvoiding-Learning-Shortcutï¼‰" class="headerlink" title="é¿å…å­¦ä¹ æ·å¾„ï¼ˆAvoiding Learning Shortcutï¼‰"></a>é¿å…å­¦ä¹ æ·å¾„ï¼ˆAvoiding Learning Shortcutï¼‰</h3><p>æ·å¾„å­¦ä¹ ï¼ˆShortcut Learningï¼‰æŒ‡çš„æ˜¯ç¥ç»ç½‘ç»œåå¥½å­¦ä¹ ç®€å•çš„ç‰¹å¾ï¼Œè¿™äº›ç®€å•ç‰¹å¾èƒ½åœ¨è®­ç»ƒé›†ä¸Šè¡¨ç°å¾—å¾ˆå¥½ï¼Œä½†å¾ˆéš¾å­¦åˆ°ä¸ä»»åŠ¡ç›¸å…³çš„ç‰¹å¾<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="Shortcut Learning in Deep Neural Networks">[4]</span></a></sup>ï¼Œä»è€Œå½±å“æ³›åŒ–æ€§ã€‚ä¾‹å¦‚ï¼ŒåŒºåˆ†ä¸åŒé¢œè‰²çš„æ•°å­—æ—¶ï¼Œç¥ç»ç½‘ç»œå¯èƒ½æ›´å¤šåœ°å­¦åˆ°é¢œè‰²ç›¸å…³çš„ç‰¹å¾ï¼Œè€Œä¸æ˜¯å½¢çŠ¶å’Œè½®å»“ç›¸å…³çš„ç‰¹å¾ã€‚è¿™æ˜¯ä¸€ç§biasï¼Œç†æ‰€å½“ç„¶åœ°ä¼šå½±å“æ³›åŒ–æ€§ã€‚åœ¨é¢†åŸŸæ³›åŒ–ä¸­ï¼Œæ¯ä¸ªåŸŸéƒ½æœ‰è‡ªå·±ç‰¹å®šçš„biasï¼Œå¦‚æœç¥ç»ç½‘ç»œåªå­¦åˆ°äº†æ¯ä¸ªç±»çš„biasï¼Œé‚£ä¹ˆæ³›åŒ–æ€§èƒ½ç»å¯¹å¤§æ‰“æŠ˜æ‰£ï¼</p><blockquote><p>åˆçœ‹æ˜¯ä¸€ä¸ªæ–°é¢–çš„è§’åº¦ï¼Œä½†ç»†æƒ³ï¼Œè¿™ä¸å°±æ˜¯è§£å†³é¢†åŸŸæ³›åŒ–ä¸­å¸¸è°ˆçš„domain-specific biasé—®é¢˜å—ï¼Ÿä¸è¿‡åæ¥å†ä»”ç»†æƒ³äº†ä¸‹ï¼Œè¿™é‡Œçš„biaså¯èƒ½æ¯”è¾ƒç‰¹æ®Šï¼Œæ˜¯èƒ½å¤Ÿå¼•å‘shortcut learningçš„biasï¼Œæ˜¯ä¸ä»»åŠ¡æ— å…³ä½†å´é€ æˆå½±å“çš„biasï¼Œå’Œé‚£äº›æ•°æ®ä¸å¹³è¡¡ä¹‹ç±»çš„biasæœ‰ç‚¹ä¸åŒã€‚æˆ‘å¯¹è¿™ä¸ªæ–¹å‘è¿˜æ˜¯å¾ˆæ„Ÿå…´è¶£çš„ï¼Œå¾—çœ‹ä¸‹æ–‡çŒ®ä¸­æ˜¯å¦‚ä½•å®šä¹‰shortcutçš„~</p></blockquote><h3 id="å› æœè¡¨å¾å­¦ä¹ ï¼ˆCausal-Representation-Learningï¼‰"><a href="#å› æœè¡¨å¾å­¦ä¹ ï¼ˆCausal-Representation-Learningï¼‰" class="headerlink" title="å› æœè¡¨å¾å­¦ä¹ ï¼ˆCausal Representation Learningï¼‰"></a>å› æœè¡¨å¾å­¦ä¹ ï¼ˆCausal Representation Learningï¼‰</h3><blockquote><p>å› æœæ¨æ–­+è¡¨ç¤ºå­¦ä¹  æˆ‘èµŒäº”æ¯›é’±ï¼Œç»å¯¹æ˜¯æœªæ¥è“¬å‹ƒå‘å±•çš„æ–¹å‘ï¼Œæ˜¯è¿ˆå‘ä¸‹ä¸€æ³¢äººå·¥æ™ºèƒ½æµªæ½®çš„å…³é”®ï¼ˆè¿™é‡Œä½©æœå‘¨Sirçš„çœ¼å…‰ï¼ï¼‰</p></blockquote><p>å½“å‰ä¸»æµçš„è¡¨ç¤ºå­¦ä¹ æ–¹æ³•æ˜¯ä¸ºäº†å­¦åˆ°æ•°æ®$X$åˆ°æ ‡ç­¾$Y$çš„ä¸€ä¸ªæ˜ å°„$P(Y|X)$ï¼Œä½†æ˜¯è¿™æ ·å­¦å¾—çš„è¡¨ç¤ºéš¾ä»¥å¤„ç†OODçš„æ•°æ®ã€‚ä¸€ç§å¯èƒ½çš„è§£å†³æ–¹æ³•æ˜¯é€šè¿‡ç”Ÿæˆæ¨¡å‹ï¼Œå¦‚autoencoderï¼Œç›´æ¥å»ºæ¨¡$P(X,Y)$ï¼Œè¿™å¯èƒ½ä¼šæé«˜é²æ£’æ€§å’Œæ³›åŒ–æ€§ã€‚</p><blockquote><p>è¡¨ç¤ºå­¦ä¹ ç›¸å…³çš„å†…å®¹æ˜¯å¥½å­¦çš„ï¼Œä½†å› æœæ¨æ–­æ¶‰åŠçš„ä¸œè¥¿å¾ˆå¤šï¼Œå¾ˆæ·±ï¼Œè™½ç„¶è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ–¹å‘ï¼Œä½†æœ¬äººå¤ªèœäº†ï¼Œåœ¨åŸºç¡€æ²¡æœ‰æ‰“ç‰¢ä¹‹å‰ï¼Œæˆ‘æ˜¯ç»å¯¹ä¸ä¼šç¢°çš„~</p></blockquote><h3 id="åˆ©ç”¨è¾…åŠ©ä¿¡æ¯ï¼ˆExploiting-Side-Informationï¼‰"><a href="#åˆ©ç”¨è¾…åŠ©ä¿¡æ¯ï¼ˆExploiting-Side-Informationï¼‰" class="headerlink" title="åˆ©ç”¨è¾…åŠ©ä¿¡æ¯ï¼ˆExploiting Side Informationï¼‰"></a>åˆ©ç”¨è¾…åŠ©ä¿¡æ¯ï¼ˆExploiting Side Informationï¼‰</h3><p>è¾…åŠ©ä¿¡æ¯å¯ä»¥ç†è§£ä¸ºä¸€äº›æœ‰ç”¨çš„åœºå¤–å› ç´ ï¼Œæ¯”å¦‚ç‰©ä½“æ£€æµ‹ï¼Œå¤§éƒ¨åˆ†äººç”¨çš„æ˜¯RGBä¿¡æ¯ï¼Œä½†å¦‚æœèƒ½å¤Ÿå¾—åˆ°å›¾åƒçš„æ·±åº¦ä¿¡æ¯RGB-Dï¼Œé‚£ä¹ˆå°†æé«˜æ£€æµ‹çš„å‡†ç¡®ç‡ã€‚åœ¨é¢†åŸŸæ³›åŒ–ä¸­ï¼Œè¿‘æœŸæœ‰äº›å·¥ä½œæŒ–æ˜äº†æ•°æ®çš„å±æ€§ä¿¡æ¯ï¼Œæ¯”å¦‚é¢œè‰²ã€å½¢çŠ¶ã€æ¡çº¹ç­‰ï¼Œ<strong>è¿™äº›å±æ€§ä¿¡æ¯æ˜¯é€šç”¨çš„ï¼Œä¸domain-specific biasæ— å…³</strong>ï¼åœ¨zero-shot learningä¸­ï¼ŒæŒ–æ˜å±æ€§ä¿¡æ¯å·²ç»æˆä¸ºäº†æ£€æµ‹æ–°ç±»çš„ä¸€ç§å¸¸ç”¨æ–¹æ³•ã€‚</p><blockquote><p>çœ‹å®Œåæœ‰ä¸€ä¸ªé—®é¢˜ï¼šå¦‚ä½•ç¡®ä¿åˆ©ç”¨åˆ°çš„è¾…åŠ©ä¿¡æ¯ä¸domain-specific biasæ— å…³ï¼Ÿå°±ç®—å¾ˆé€šç”¨çš„å±æ€§ï¼Œæ¯”å¦‚é¢œè‰²ï¼Œä¹Ÿè¦åˆ†åœºæ™¯å§ï¼Ÿè¿›ä¸€æ­¥ï¼Œå¦‚æœè¦ä¿è¯è¾…åŠ©ä¿¡æ¯çš„é€šç”¨æ€§ï¼Œé‚£ä¹ˆå‰æ·±åº¦å­¦ä¹ æ—¶ä»£è¿ç”¨çš„ç‰¹å¾æ¯”å¦‚HoGæ˜¯å¦å¯ä»¥æœ‰ç”¨æ­¦ä¹‹åœ°ï¼Ÿ</p></blockquote><h3 id="è¿ç§»å­¦ä¹ ï¼ˆTransfer-Learningï¼‰"><a href="#è¿ç§»å­¦ä¹ ï¼ˆTransfer-Learningï¼‰" class="headerlink" title="è¿ç§»å­¦ä¹ ï¼ˆTransfer Learningï¼‰"></a>è¿ç§»å­¦ä¹ ï¼ˆTransfer Learningï¼‰</h3><p>è¿™é‡Œçš„è¿ç§»å­¦ä¹ ç‰¹æŒ‡Synthetic-to-realåœºæ™¯ä¸‹çš„è¿ç§»å­¦ä¹ ï¼Œå³ä»çœŸå®æ•°æ®é›†ä¸Šè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¦èƒ½å¤Ÿè¿ç§»åˆ°ä¸‹æ¸¸åˆæˆçš„æ•°æ®ä¸Šï¼ŒåŒæ—¶ï¼Œè¦èƒ½å¤Ÿä¾ç„¶ä¿æŒçœŸå®æ•°æ®é›†ä¸Šå­¦åˆ°çš„çŸ¥è¯†ï¼Œè¯´ç™½äº†ï¼Œå°±æ˜¯æŒç»­å­¦ä¹ ï¼ˆContinual Learningï¼‰ã€‚</p><blockquote><p>æ²¡ææ‡‚è¿™ä¸ªåœºæ™¯å’ŒæŒç»­å­¦ä¹ çš„åŒºåˆ«æ‰€åœ¨ï¼Œä»¥åŠå®ƒä¸ºå•¥æ˜¯ä¸€ä¸ªrealistic and practicalçš„è®¾å®šï¼Ÿä¸è¿‡yysyï¼Œä¹‹å‰æè¿‡ä¸€æ®µæ—¶é—´çš„æŒç»­å­¦ä¹ ï¼Œè¯´ä¸å®šå¯ä»¥æŒ–å‘ï¼ˆç¬‘~</p></blockquote><h3 id="åŠç›‘ç£é¢†åŸŸæ³›åŒ–ï¼ˆSemi-Supervised-Domain-Generalizationï¼‰"><a href="#åŠç›‘ç£é¢†åŸŸæ³›åŒ–ï¼ˆSemi-Supervised-Domain-Generalizationï¼‰" class="headerlink" title="åŠç›‘ç£é¢†åŸŸæ³›åŒ–ï¼ˆSemi-Supervised Domain Generalizationï¼‰"></a>åŠç›‘ç£é¢†åŸŸæ³›åŒ–ï¼ˆSemi-Supervised Domain Generalizationï¼‰</h3><p>ç»å…¸A+B</p><blockquote><p>ä¸è¯´äº†ï¼Œçœ‹åå­—éƒ½çŒœå¾—åˆ°å¹²å•¥ï¼Œå¾ˆå·çš„ä¸€ä¸ªæ–¹å‘</p></blockquote><h3 id="å¼€æ”¾åŸŸæ³›åŒ–ï¼ˆOpen-Domain-Generalizationï¼‰"><a href="#å¼€æ”¾åŸŸæ³›åŒ–ï¼ˆOpen-Domain-Generalizationï¼‰" class="headerlink" title="å¼€æ”¾åŸŸæ³›åŒ–ï¼ˆOpen Domain Generalizationï¼‰"></a>å¼€æ”¾åŸŸæ³›åŒ–ï¼ˆOpen Domain Generalizationï¼‰</h3><p>å¯ä»¥è®¤ä¸ºæ˜¯ä¸€ç§æ–°çš„è®¾å®šï¼ŒæºåŸŸæ˜¯å¼‚è´¨çš„ï¼Œå³åŸŸä¸åŸŸä¹‹é—´ä¸ä»…æ•°æ®åˆ†å¸ƒä¸åŒï¼Œè€Œä¸”å«æœ‰ä¸åŒçš„æ ‡è®°ç©ºé—´ï¼Œé’ˆå¯¹ç›®æ ‡åŸŸï¼Œæ¨¡å‹è¦èƒ½å¤Ÿè¯†åˆ«å‡ºè§è¿‡çš„ç±»åˆ«ï¼Œå¹¶ä¸”æ£€æµ‹å‡ºæ²¡æœ‰è§è¿‡çš„ç±»åˆ«ã€‚</p><blockquote><p>è¿™æ˜¯ä¸€ä¸ªå’ŒHeterogeneous Domain Generalizationå’ŒOpen-set Recognitionéƒ½æœ‰å…³çš„ä¸€ä¸ªé—®é¢˜ï¼Œéš¾åº¦å¯æƒ³è€ŒçŸ¥ã€‚</p></blockquote><h2 id="è¯„ä»·åŸºå‡†"><a href="#è¯„ä»·åŸºå‡†" class="headerlink" title="è¯„ä»·åŸºå‡†"></a>è¯„ä»·åŸºå‡†</h2><h3 id="æŒç»­é¢†åŸŸæ³›åŒ–å­¦ä¹ ï¼ˆIncremental-Learning-Domain-Generalizationï¼‰"><a href="#æŒç»­é¢†åŸŸæ³›åŒ–å­¦ä¹ ï¼ˆIncremental-Learning-Domain-Generalizationï¼‰" class="headerlink" title="æŒç»­é¢†åŸŸæ³›åŒ–å­¦ä¹ ï¼ˆIncremental Learning + Domain Generalizationï¼‰"></a>æŒç»­é¢†åŸŸæ³›åŒ–å­¦ä¹ ï¼ˆIncremental Learning + Domain Generalizationï¼‰</h3><p>ä»¥å¾€é¢†åŸŸæ³›åŒ–çš„å·¥ä½œåˆ©ç”¨åˆ°çš„è®­ç»ƒæ•°æ®æ˜¯å›ºå®šçš„ï¼Œä¸ä¼šå‘ç”Ÿå˜åŒ–ï¼Œä½†æ˜¯åœ¨å®é™…åœºæ™¯ä¸­ï¼Œè®­ç»ƒæ•°æ®å¯èƒ½æ˜¯åŠ¨æ€åˆ°æ¥çš„ï¼Œè¿™ä¸ªæ—¶å€™ï¼Œå°±éœ€è¦é’ˆå¯¹æºåŸŸçš„æŒç»­é¢†åŸŸæ³›åŒ–å­¦ä¹ ã€‚ä½†æ˜¯ï¼Œæœ‰å¦‚ä¸‹3ä¸ªé—®é¢˜éœ€è¦è§£å†³ï¼š1ï¼‰åœ¨æ–°åˆ°æ¥çš„æ•°æ®ä¸Šï¼Œæ€æ ·fine-tuneæ¨¡å‹ï¼Œè€Œä¸æ˜¯é‡æ–°è®­ç»ƒä¸€éï¼Ÿ2ï¼‰æ€æ ·é¿å…ç¾éš¾æ€§é—å¿˜ä»¥åŠè¿‡æ‹Ÿåˆæ–°æ•°æ®ï¼Ÿ3ï¼‰æ€æ ·åˆ¤æ–­æ–°æ•°æ®å¯¹æ¨¡å‹æ³›åŒ–æ€§èƒ½çš„å½±å“ï¼Œæœ‰ç›Šè¿˜æ˜¯æœ‰å®³ï¼Ÿ</p><blockquote><p>æˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªå¾ˆæœ‰æ„ä¹‰çš„æ–¹å‘ï¼Œå¦‚æœèƒ½æœ‰ä¸€ä¸ªå¥½çš„æ–¹æ¡ˆï¼Œå°†æœ‰å¾ˆå¤§çš„ç°å®æ„ä¹‰ï¼Œå€¼å¾—å…³æ³¨ï¼</p></blockquote><h3 id="å¼‚è´¨åŸŸå˜åŒ–ï¼ˆHeterogeneous-Domain-Shiftï¼‰"><a href="#å¼‚è´¨åŸŸå˜åŒ–ï¼ˆHeterogeneous-Domain-Shiftï¼‰" class="headerlink" title="å¼‚è´¨åŸŸå˜åŒ–ï¼ˆHeterogeneous Domain Shiftï¼‰"></a>å¼‚è´¨åŸŸå˜åŒ–ï¼ˆHeterogeneous Domain Shiftï¼‰</h3><p>å½“å‰é¢†åŸŸæ³›åŒ–ç›¸å…³çš„å·¥ä½œï¼ŒæºåŸŸå’Œç›®æ ‡åŸŸé«˜åº¦ç›¸å…³ï¼Œæ¯”å¦‚åªæ˜¯ä¸€äº›é¢œè‰²åè½¬ã€å›¾åƒæ—‹è½¬ä¹‹ç±»çš„ï¼Œå¾ˆå°‘è€ƒè™‘åˆ°å¼‚æ„å˜åŒ–ï¼Œæ¯”å¦‚æºåŸŸæ•°æ®æ˜¯ç‰©ä½“çš„ç…§ç‰‡ã€æ²¹ç”»å’Œç®€ç¬”ç”»ï¼Œä½†æ˜¯ç›®æ ‡åŸŸå´æ˜¯æ–°è§†è§’ä¸‹çš„å›¾ç‰‡ã€‚</p><blockquote><p>è¿™ä¸ªè®¾å®šè™½ç„¶å¾ˆéš¾ï¼Œä½†å´å¯¹ç°å®åº”ç”¨å¾ˆæœ‰æ„ä¹‰ã€‚</p></blockquote><h1 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h1><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a href="https://ui.adsabs.harvard.edu/abs/2021arXiv210302503Z/abstract#:~:text=%EE%80%80Domain%20Generalization%20in%20Vision%3A%20A%20Survey%EE%80%81.%20%EE%80%80Generalization%EE%80%81%20to,often%20violated%20in%20practice%20due%20to%20%EE%80%80domain%EE%80%81%20shift.">Domain Generalization in Vision: A Survey</a><a href="#fnref:1" rev="footnote" class="footnote-backref"> â†©</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a href="https://iclr.cc/virtual/2021/spotlight/3479">Tent: Fully Test-Time Adaptation by Entropy Minimization</a><a href="#fnref:2" rev="footnote" class="footnote-backref"> â†©</a></span></span></li><li><span id="fn:3" class="footnote-text"><span><a href="https://openreview.net/forum?id=UH-cmocLJC">How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks</a><a href="#fnref:3" rev="footnote" class="footnote-backref"> â†©</a></span></span></li><li><span id="fn:4" class="footnote-text"><span><a href="https://www.nature.com/articles/s42256-020-00257-z#:~:text=Fig.%201%3A%20Examples%20of%20shortcut%20learning.%20Deep%20neural,pattern%20can%20be%20observed%20in%20many%20real-world%20applications.">Shortcut Learning in Deep Neural Networks</a><a href="#fnref:4" rev="footnote" class="footnote-backref"> â†©</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Tech</category>
      
      <category>DL</category>
      
      <category>DG</category>
      
    </categories>
    
    
    <tags>
      
      <tag>paper</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(Paper Reading) Adaptive Methods for Real-World Domain Generalization</title>
    <link href="/2021/12/30/PR-Adaptive-Methods-Real-World-DG/"/>
    <url>/2021/12/30/PR-Adaptive-Methods-Real-World-DG/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul><li>å»ºç«‹äº†ä¸€ä¸ªDGå¤§è§„æ¨¡æ•°æ®é›†Geo-YFCCï¼Œè€ƒè™‘åˆ°äº†é•¿å°¾åˆ†å¸ƒ</li><li>ç”¨äº†æœ€naiveçš„æ–¹æ³•ERMï¼Œä½†å´å–å¾—äº†éå¸¸å¥½çš„æ•ˆæœ</li><li>â€œIn our work, we propose an adaptive classifier that can be adapted to any new domain using very few unlabelled samples without any further trainingâ€</li></ul><h1 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h1><h2 id="Core-Idea"><a href="#Core-Idea" class="headerlink" title="Core Idea"></a>Core Idea</h2><p>åœ¨æµ‹è¯•æ—¶ï¼Œåˆ©ç”¨å°‘é‡æ— æ ‡è®°æ ·æœ¬åˆ»ç”»unseen domainä¿¡æ¯ï¼Œç„¶åç”¨å…¶è¾…åŠ©åˆ†ç±»ã€‚</p><h2 id="Prototypical-Domain-Embeddings"><a href="#Prototypical-Domain-Embeddings" class="headerlink" title="Prototypical Domain Embeddings"></a>Prototypical Domain Embeddings</h2><p>Prototypical NetworksçœŸå¥½ç”¨ï¼ç”¨ä¸€ä¸ªåŸŸä¸­å›¾ç‰‡ç‰¹å¾çš„å¹³å‡å€¼æ¥åˆ»ç”»åŸŸä¿¡æ¯ï¼Œç†è®ºåŸºç¡€æ˜¯Kenerl Mean Embeddings(KME)ã€‚è®­ç»ƒæ—¶çš„lossæ˜¯ï¼š</p><script type="math/tex; mode=display">p_{\boldsymbol{\theta}}(\mathbf{x} \in D)=\frac{\exp \left(-\left\|\boldsymbol{\mu}(\widehat{D})-\Phi_{\mathcal{D}}(\mathbf{x})\right\|_{2}^{2}\right)}{\sum_{i=1}^{N_{t}} \exp \left(-\left\|\boldsymbol{\mu}\left(\widehat{D}_{i}\right)-\Phi_{\mathcal{D}}(\mathbf{x})\right\|_{2}^{2}\right)}</script><p>å…¶ä¸­ï¼Œ$\Phi_{D}(\cdot)$æ˜¯ç‰¹å¾æå–ç½‘ç»œã€‚</p><h2 id="ERM-on-Augmented-Inputs"><a href="#ERM-on-Augmented-Inputs" class="headerlink" title="ERM on Augmented Inputs"></a>ERM on Augmented Inputs</h2><p>æµ‹è¯•æ—¶ï¼Œè®¡ç®—å›¾ç‰‡ç‰¹å¾åŠç‰¹å¾å¹³å‡å€¼ï¼ˆåŸŸä¿¡æ¯ï¼‰ï¼Œconcatenateä¸€ä¸‹è¾“å…¥åˆ†ç±»å™¨ã€‚</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><p>æ„é€ äº†ä¸¤ä¸ªæ•°æ®é›†ï¼šGeo-YFCCå’ŒLT-ImageNetï¼Œæ•°æ®é‡éƒ½åœ¨ç™¾ä¸‡é‡çº§ï¼Œ4å¼ V100èµ·æ­¥ã€‚</p>]]></content>
    
    
    <categories>
      
      <category>Tech</category>
      
      <category>DL</category>
      
      <category>DG</category>
      
    </categories>
    
    
    <tags>
      
      <tag>paper</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(Paper Reading) è¿‘æœŸå…³äºé¢†åŸŸæ³›åŒ–æ–‡ç« çš„å½’çº³æ•´ç†</title>
    <link href="/2021/12/22/PR-Domain-Generalization/"/>
    <url>/2021/12/22/PR-Domain-Generalization/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>é¢†åŸŸæ³›åŒ–ï¼ˆDomain Generalization, DGï¼‰ï¼Œä¸åŒäºé¢†åŸŸè‡ªé€‚åº”ï¼ˆDomain Adaptation, DAï¼‰ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ— æ³•æ¥è§¦åˆ°ç›®æ ‡åŸŸçš„æ•°æ®ï¼Œå› æ­¤æ¯”DAæ›´åŠ å›°éš¾ï¼Œæ˜¯ä¸€ä¸ªæ–°å‘ã€‚</p><h1 id="Test-Time-Classifier-Adjustment-Module-for-Model-Agnostic-Domain-Generalization-T3A"><a href="#Test-Time-Classifier-Adjustment-Module-for-Model-Agnostic-Domain-Generalization-T3A" class="headerlink" title="Test-Time Classifier Adjustment Module for Model-Agnostic Domain Generalization (T3A)"></a>Test-Time Classifier Adjustment Module for Model-Agnostic Domain Generalization (T3A)</h1><h2 id="Highlights"><a href="#Highlights" class="headerlink" title="Highlights:"></a>Highlights:</h2><ul><li>Source-free, ä¸å­˜å‚¨è®­ç»ƒæ•°æ®</li><li>Back-propagation-free, åœ¨æµ‹è¯•é˜¶æ®µä¸è®­ç»ƒ</li><li>Can be applied to online inference</li></ul><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><script type="math/tex; mode=display">\mathbb{S}_{t}^{k}= \begin{cases}\mathbb{S}_{t-1}^{k} \cup\left\{\frac{f_{\boldsymbol{\theta}}(\boldsymbol{x})}{\left\|f_{\boldsymbol{\theta}}(\boldsymbol{x})\right\|}\right\} & \text { if } \hat{y}=y^{k} \\ \mathbb{S}_{t-1}^{k} & \text { else }\end{cases}</script><script type="math/tex; mode=display">\underset{y_{k}}{\arg \max } \gamma_{c}\left(Y=y_{k} \mid f_{\boldsymbol{\theta}}(\boldsymbol{x})\right)=\frac{\exp \left(\boldsymbol{z} \cdot \boldsymbol{c}^{k}\right)}{\sum_{j} \exp \left(\boldsymbol{z} \cdot \boldsymbol{c}^{j}\right)},</script><script type="math/tex; mode=display">\boldsymbol{c}^{k}=\frac{1}{\left|\mathbb{S}^{k}\right|} \sum_{\boldsymbol{z} \in \mathbb{S}_{t}^{k}} \boldsymbol{z}</script><p>ç®€å•æ¥è¯´ï¼Œå°±æ˜¯æŠŠåœ¨ä¸åŒåŸŸä¸Šè®­ç»ƒå¥½çš„æ¨¡å‹å½“ä½œä¸€ä¸ªç‰¹å¾æå–å™¨ï¼Œç„¶ååœ¨æµ‹è¯•æ•°æ®ä¸Šé‡‡ç”¨ä¸€ä¸ªæœ€è¿‘é‚»åˆ†ç±»ï¼Œéœ€è¦æ³¨æ„ï¼Œå› ä¸ºé‡‡ç”¨äº†æœ€è¿‘é‚»ï¼Œæ‰€ä»¥éœ€è¦ç»™æ¯ä¸ªç±»ç»´æŒä¸€ä¸ªç±»åˆ«åŸå‹ï¼Œè¿™ä¸ªç±»åˆ«åŸå‹ä¼šéšç€æµ‹è¯•æ•°æ®çš„å˜åŒ–è€ŒåŠ¨æ€å˜åŒ–ã€‚</p><h2 id="Learn-from-this-paper"><a href="#Learn-from-this-paper" class="headerlink" title="Learn from this paper"></a>Learn from this paper</h2><ul><li>Try to create a new reasonable setting, and prototype is a breakthrough point.</li></ul><h1 id="Generalization-on-Unseen-Domains-via-Inference-time-Label-Preserving-Target"><a href="#Generalization-on-Unseen-Domains-via-Inference-time-Label-Preserving-Target" class="headerlink" title="Generalization on Unseen Domains via Inference-time Label-Preserving Target"></a>Generalization on Unseen Domains via Inference-time Label-Preserving Target</h1><h2 id="Highlights-1"><a href="#Highlights-1" class="headerlink" title="Highlights"></a>Highlights</h2><ul><li>Use test data to implement complex operations</li></ul><h2 id="Method-1"><a href="#Method-1" class="headerlink" title="Method"></a>Method</h2><p><img src="https://note.youdao.com/yws/api/personal/file/WEBddd2c87b268043cd225ca57a99136692?method=download&amp;shareKey=8fa1a22223aa9b5db2d00ab13a281cfe" alt=""><br>ç®€å•æ¥è¯´ï¼Œåœ¨æºåŸŸä¸Šåˆ©ç”¨å¯¹æ¯”å­¦ä¹ çš„æ€è·¯è®­ç»ƒä¸€ä¸ªç±»åˆ«ç‰¹å¾è€¦åˆçš„ç¥ç»ç½‘ç»œï¼Œå…³æ³¨ä¸åŒåŸŸä¸­ç›¸åŒç±»åˆ«æ•°æ®çš„ç‰¹å¾ä¸€è‡´æ€§ï¼Œç„¶ååœ¨ç‰¹å¾ç©ºé—´ä¸­è®­ç»ƒä¸€ä¸ªç”Ÿæˆæ¨¡å‹æ‹Ÿåˆç±»åˆ«ç‰¹å¾çš„åˆ†å¸ƒã€‚å¯¹äºæµ‹è¯•å›¾ç‰‡ï¼Œç¥ç»ç½‘ç»œæå–ç‰¹å¾åï¼Œåˆ©ç”¨ç”Ÿæˆæ¨¡å‹æ‰¾åˆ°ç”Ÿæˆä¸€ä¸ªå’Œæµ‹è¯•å›¾ç‰‡ç‰¹å¾æœ€è¿‘çš„ç‰¹å¾ï¼Œè¯¥ç”Ÿæˆç‰¹å¾ç±»åˆ«å³ä¸ºçœŸå®ç±»åˆ«ã€‚</p><h2 id="Learn-from-this-paper-1"><a href="#Learn-from-this-paper-1" class="headerlink" title="Learn from this paper"></a>Learn from this paper</h2><ul><li>å¯¹ç”Ÿæˆæ¨¡å‹çš„è¿™ç§ç”¨æ³•æˆ‘æ˜¯ç¬¬ä¸€æ¬¡è§ï¼ˆä¸Šå›¾Dï¼‰ï¼Œå†æ¬¡éªŒè¯äº†æ•°æ®ç”ŸæˆçœŸçš„æ˜¯åˆ·ç‚¹åˆ©å™¨ï¼ä½†æ˜¯æˆ‘å¯¹è¿™ç¯‡æ–‡ç« æ˜¯å¦èƒ½å®Œæ•´å¤ç°å­˜ç–‘ã€‚</li></ul><h1 id="Tent-Fully-Test-time-Adaptation-by-Entropy-Minimization"><a href="#Tent-Fully-Test-time-Adaptation-by-Entropy-Minimization" class="headerlink" title="Tent: Fully Test-time Adaptation by Entropy Minimization"></a>Tent: Fully Test-time Adaptation by Entropy Minimization</h1><h2 id="Highlights-2"><a href="#Highlights-2" class="headerlink" title="Highlights"></a>Highlights</h2><ul><li>â€œEntropy is related to shifts due to corruption, as more corruption results in more entropy, with a strong rank correlation to the loss for image classification as the level of corruption increases.â€</li><li>Source free, just use test data to optimize the whole model.</li></ul><h2 id="Method-2"><a href="#Method-2" class="headerlink" title="Method"></a>Method</h2><p><img src="https://note.youdao.com/yws/api/personal/file/WEB306c48d84d4a177c3d8747c3252d7671?method=download&amp;shareKey=d1a976e91b02e4869a84496dfcf3f008" alt=""><br>ç®€å•æ¥è¯´ï¼Œåœ¨æµ‹è¯•é˜¶æ®µï¼Œç›®æ ‡å‡½æ•°ä»CEå˜ä¸ºEntropyï¼Œå¹¶ä¸”æ›´æ–°å‚æ•°æ—¶ï¼Œåªæ›´æ–°BNå±‚ä¸­çš„$\gamma$å’Œ$\beta$ã€‚</p><h2 id="Learn-from-this-paper-2"><a href="#Learn-from-this-paper-2" class="headerlink" title="Learn from this paper"></a>Learn from this paper</h2><ul><li>è®©æˆ‘ç†æ¸…æ¥šäº†DGä¸­å„ä¸ªé¢†åŸŸçš„å…³ç³»ï¼Œsettingè¯´çš„å¥½å•Šï¼<br><img src="https://note.youdao.com/yws/api/personal/file/WEB1291067c5b889241a9001968705a44e4?method=download&amp;shareKey=71db0eaba91f486d313b808b36a5df71" alt=""></li></ul>]]></content>
    
    
    <categories>
      
      <category>Tech</category>
      
      <category>DL</category>
      
      <category>DG</category>
      
    </categories>
    
    
    <tags>
      
      <tag>paper</tag>
      
      <tag>summary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(Paper Reading) Efficient Deep Learning Survey A Survey on Making Deep Learning Models Smaller, Faster, and Better</title>
    <link href="/2021/12/04/PR-Efficient-Deep-Learning-Survey/"/>
    <url>/2021/12/04/PR-Efficient-Deep-Learning-Survey/</url>
    
    <content type="html"><![CDATA[<p>Published by Google Research.</p><h2 id="1-Main-challenges-in-deep-learning-areas"><a href="#1-Main-challenges-in-deep-learning-areas" class="headerlink" title="1. Main challenges in deep learning areas"></a>1. Main challenges in deep learning areas</h2><ul><li><strong>Sustainable Server-Side Scaling</strong>. deploying and letting inference run for over a long period of time could still turn out to be expensive in terms of consumption of server-side RAM, CPU, etc.</li><li><strong>Enabling On-Device Deployment</strong>. Certain deep learning applications need to run real time on IoT and smart devices (where the model inference happens directly on the device), for a multitude of reasons (privacy, connectivity, responsiveness).</li><li><strong>Privacy &amp; Data Sensitivity</strong>. Being able to use as little data as possible for training is critical when the user-data might be sensitive.</li><li><strong>New Applications</strong>. Certain new applications offer new constraints (around model quality<br>or footprint) that existing off-the-shelf models might not be able to address.</li><li><strong>Explosion of Models</strong>. While a singular model might work well, training and/or deploying multiple models on the same infrastructure (colocation) for different applications might end up exhausting the available resources. (Multi-task learning?)</li></ul><p>Specifically, the common theme around the above challenges is <em>efficiency</em>, which can be categorized into two aspects:</p><ul><li>Inference Efficiency</li><li>Training Efficiency</li></ul><p>Our goal is to train and deploy pareto-optimal models with respect to model quality and its footprint.</p><h2 id="2-A-mental-model"><a href="#2-A-mental-model" class="headerlink" title="2. A mental model"></a>2. A mental model</h2><p><img src="https://note.youdao.com/yws/api/personal/file/WEBcfe8440e5764dc0248ff1c33066dce7d?method=download&amp;shareKey=4407939a456a1e27e2b393d80cca4a52" alt="A mental model for thinking about algorithms, techniques, and tools related to efficiency in Deep Learning"></p><ul><li><strong>Compression Techniques</strong>. Pruning, quantization etc.</li><li><strong>Learning Techniques</strong>. Distillation etc.</li><li><strong>Automation</strong>. HPO, NAS etc.</li><li><strong>Efficient Architectures</strong>. Some fundamental blocks, such as conv, attention.</li><li><strong>Infrastructure</strong>. TF, Pytorch etc.</li></ul><h2 id="3-Landscape-of-Efficient-Deep-Learning"><a href="#3-Landscape-of-Efficient-Deep-Learning" class="headerlink" title="3. Landscape of Efficient Deep Learning"></a>3. Landscape of Efficient Deep Learning</h2><h3 id="3-1-Compression-Techniques"><a href="#3-1-Compression-Techniques" class="headerlink" title="3.1 Compression Techniques"></a>3.1 Compression Techniques</h3><p>In some cases if the model is over-parameterized, these techniques can improve model generalization.</p><ul><li><strong>Pruning</strong>, prefer structured pruning</li><li><strong>Quantization</strong>,  <ul><li><strong>Weight quantization</strong>, we can map the minimum weight value $(ğ‘¥_{ğ‘šğ‘–ğ‘›})$ in that matrix to 0, and the maximum value (ğ‘¥ğ‘šğ‘ğ‘¥ ) to $2^{b} âˆ’ 1$ (where ğ‘ is the number of bits of precision, and ğ‘ &lt; 32). XNOR-Net, Binarized Neural Networks and others use ğ‘ = 1, and thus have weight matrices which just have two possible values 0 or 1, and the quantization function there is simply the $\sign(ğ‘¥)$ function (assuming the weights are symmetrically distributed around 0). Binary quantization <strong>still need support from the underlying hardware</strong>. </li><li><strong>Activation quantization</strong>, This means all intermediate layer inputs and outputs are also in fixed-point, and there is no need to dequantize the weight matrices since they can be used directly along with the inputs. </li><li><font color=red><strong>Quantization-aware training (QAT)</strong></font>, post-training quantization leads to quality loss inference. <strong>Fake quantization</strong>, the training happens in floating-point but the forward-pass simulates the quantization behavior during inference.<br><img src="https://note.youdao.com/yws/api/personal/file/WEB37a680e93db48a8953105f44a62c1327?method=download&amp;shareKey=659a4e53a58a749caf8e6403db38bf16" alt=""><br>QAT is good, but tools like TF Lite have made it easy to rely on post-training quantization. For performance reasons, it is best to consider the common operations that follow a typical layer such as Batch-Norm, Activation, etc. and â€˜foldâ€™ them in the quantization operations.</li></ul></li><li>Other Compression Techniques. There are other compression techniques like Low-Rank<br>Matrix Factorization, K-Means Clustering, Weight-Sharing etc. which are also actively being used for model compression and might be suitable for further compressing hotspots in a model.</li></ul><h3 id="3-2-Learning-Techniques"><a href="#3-2-Learning-Techniques" class="headerlink" title="3.2 Learning Techniques"></a>3.2 Learning Techniques</h3><ul><li><strong>Distillation</strong>, transfer ensembled models in weakly supervised learning to a smaller model (2006). Knowledge distillation, in my opinion, the large model provides informative relations among classes. Strategies for intermediate-layer distillation have also shown to be effective in the case of complex networks.</li><li><p><strong>Data augmentation</strong> (training efficiency), various transformations</p><ul><li><strong>label-invariant transformations</strong>, <em>e.g.</em>, flipping, cropping, rotations.</li><li><strong>Label-Mixing transformations</strong>, Mixup, The intuition is that the model should be<br>able to extract out features that are relevant for both the classes.</li><li><strong>Data-Dependent transformations</strong>, In this case, transformations are chosen such that they maximize the loss for that example [56], or are adversarially chosen so as to fool the classifier.</li><li><strong>Synthetic sampling</strong>, SMOTE, GAN</li><li><p><strong>Composition of transformations</strong>, combing above methods</p><p>Auto-Augment sounds practicalâ€¦</p></li></ul></li><li><strong>Self-Supervised Learning</strong>, fine-tuning models pre-trained with Self-Supervised learning<br>are data-efficient (they converge faster, attain better quality for the same amount of labeled data when compared to training from scratch, etc.) Contrastive learning is effective. <strong>SSL provides a good pre-trained model for data-limited scenarios</strong>.</li></ul><h3 id="3-3-Automation"><a href="#3-3-Automation" class="headerlink" title="3.3 Automation"></a>3.3 Automation</h3><p>The trade-off is that these methods might require large computational resources, and hence have to be carefully applied.</p><ul><li><strong>Hyper-Parameter Optimization</strong>, Grid Search, Random Search (May not effective for high-dimensional space), Bayesian Optimization (it also makes the search sequential, though it is possible to run multiple trials in parallel, overall it will lead to some wasted trials.), Population based training (similar to evolutionary approaches), <strong>MAB algorithms</strong></li><li><strong>NAS</strong>, search space, search algorithm &amp; state, evaluation strategy. From single target accuracy to multi-goals, such as latency.</li></ul><h3 id="3-4-Efficient-Architectures"><a href="#3-4-Efficient-Architectures" class="headerlink" title="3.4 Efficient Architectures"></a>3.4 Efficient Architectures</h3><ul><li><strong>Depth-Separable Convolution</strong>, classical<br><img src=https://note.youdao.com/yws/api/personal/file/WEB94edd371460c9ac3912f34b0f9f85db3?method=download&shareKey=7715f1dfe158aeda2bcfd32dd843a0a3 style="zoom: 50%;" /></li><li><strong>Attention Mechanism &amp; Transformer Family</strong>, very hot!</li><li><strong>Random Projection Layers &amp; Models</strong>, The core-benefit of the projection operation when compared to embedding tables is ğ‘‚(ğ‘‡ ) space required instead of ğ‘‚(ğ‘‰ .ğ‘‘) (ğ‘‡ seeds required for ğ‘‡ hash functions). On the other hand, random-projection computation is ğ‘‚(ğ‘‡ ) too v/s ğ‘‚(1) for embedding table lookup. Hence, the projection layer is clearly useful when model size is the primary focus of optimization. Reduce the memory, while increasing latency.</li></ul><h3 id="3-5-Infrastructure"><a href="#3-5-Infrastructure" class="headerlink" title="3.5 Infrastructure"></a>3.5 Infrastructure</h3><ul><li>TF Lite</li><li>PyTorch Mobile</li></ul>]]></content>
    
    
    <categories>
      
      <category>Tech</category>
      
      <category>DL</category>
      
      <category>Compression</category>
      
    </categories>
    
    
    <tags>
      
      <tag>paper</tag>
      
      <tag>google</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Github + Hexo æ­å»ºåšå®¢è¸©å‘æŒ‡å—</title>
    <link href="/2021/11/03/github-hexo-write-blog/"/>
    <url>/2021/11/03/github-hexo-write-blog/</url>
    
    <content type="html"><![CDATA[<h2 id="å¼€åšè¯­"><a href="#å¼€åšè¯­" class="headerlink" title="å¼€åšè¯­"></a>å¼€åšè¯­</h2><p>ä¹‹å‰æ˜¯ç”¨é˜¿é‡Œäº‘çš„æœåŠ¡å™¨æ­å»ºåšå®¢ï¼Œä½†å­¦ç”Ÿä¼˜æƒ ç”¨å®Œäº†ï¼Œå¹´è´¹å¤ªè´µï¼Œé‚ç™½å«–GitHubé‡æ–°æ­å»ºåšå®¢ã€‚å›é¡¾ä¹‹å‰çš„å†™ä½œå†…å®¹ï¼Œæ·±æ„Ÿä¸ªäººè¾“å‡ºèƒ½åŠ›æå…¶æ¬ ç¼ºï¼Œæ•…å€Ÿå†å¼€åšå®¢ä¹‹æœºï¼Œé‡æ•´æ——é¼“ï¼Œç”¨å¿ƒå†™ä½œï¼Œä»¥ç»ƒä¸–äº‹ä¹‹æ´å¯Ÿã€æƒ…ç†ä¹‹åˆ†æã€è¡¨è¾¾ä¹‹é€»è¾‘ï¼</p><h2 id="æ­å»ºåšå®¢ä¸­çš„å‘"><a href="#æ­å»ºåšå®¢ä¸­çš„å‘" class="headerlink" title="æ­å»ºåšå®¢ä¸­çš„å‘"></a>æ­å»ºåšå®¢ä¸­çš„å‘</h2><p>Github+Hexoçš„ç»„åˆç½‘ä¸Šå·²æœ‰è®¸å¤šèµ„æ–™ï¼Œæˆ‘å‚è€ƒçš„æ˜¯è¿™ä»½çŸ¥ä¹é«˜èµæ•™ç¨‹<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="Github+Hexoæ­å»ºä¸ªäººç½‘ç«™è¯¦ç»†æ•™ç¨‹-çŸ¥ä¹é«˜èµ-å´æ¶¦">[1]</span></a></sup>ï¼Œä½†åœ¨å…·ä½“æ­å»ºè¿‡ç¨‹ä¸­ä¾ç„¶è¸©äº†ä¸å°‘å‘ï¼Œæˆ‘å°†å¡«è¿™äº›å‘çš„æ–¹æ¡ˆæ•´ç†äº†ä¸€ä¸‹ï¼Œä½ å¦‚è‹¥ä¹Ÿè¸©åˆ°äº†ç›¸ä¼¼çš„å‘ï¼Œé‚£ä¹Ÿç®—æ˜¯æœ‰ç¼˜~</p><ul><li>ä½ éœ€è¦å†githubä¸Šåˆ›å»ºä¸€ä¸ªæ–°repoï¼Œè¿™ä¸ªrepoçš„åå­—æ˜¯ï¼š<strong>ç”¨æˆ·å</strong>.github.ioï¼Œ<strong>ä¸€å®šå¾—æ˜¯ä½ githubçš„ç”¨æˆ·å</strong></li><li>é…ç½®gitå’Œhexoï¼Œè§<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="Github+Hexoæ­å»ºä¸ªäººç½‘ç«™è¯¦ç»†æ•™ç¨‹-çŸ¥ä¹é«˜èµ-å´æ¶¦">[1]</span></a></sup></li><li><code>hexo d</code>æ¨é€ç½‘ç«™ï¼Œéœ€è¦è¾“å…¥ä½ çš„ç”¨æˆ·åå’Œå¯†ç ï¼Œç„¶åå¯èƒ½ä¼šå‡ºç°å¦‚ä¸‹é—®é¢˜ï¼š<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">Support <span class="hljs-keyword">for</span> password authentication was removed on August 13, 2021. Please use a personal access token instead.<br></code></pre></td></tr></table></figure>è¿™æ˜¯ç”±äºgithubç°åœ¨å·²ç»ä¸æ”¯æŒusername-passwdè¿™å¥—è®¤è¯äº†ï¼Œå–è€Œä»£ä¹‹çš„æ˜¯ä¸ªäººtokenè®¤è¯<br>è§£å†³æ–¹æ¡ˆæ˜¯å¢æ·»Windowsæ™®é€šå‡­æ®ï¼Œå‚è€ƒ<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="github_token">[2]</span></a></sup></li><li>å³ä½¿tokené…ç½®æˆåŠŸäº†ï¼Œ<code>hexo d</code>ä»ä¼šå‡ºç°é—®é¢˜ï¼š<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">unable to access <span class="hljs-string">&#x27;https://github.com/XXX/XXX.github.io.git/&#x27;</span>: Failed to connect to github.com port 443: Timed out<br></code></pre></td></tr></table></figure>è¿™æ˜¯å¢™çš„é—®é¢˜ï¼Œè§£å†³æ–¹æ¡ˆå°±æ˜¯å…¨å±€proxyï¼Œå‚è€ƒ<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="å½“Hexoéƒ¨ç½²é‡åˆ°å¢™">[3]</span></a></sup></li><li>ä½ æ¨é€ç½‘ç«™æˆåŠŸäº†ï¼Œä½†åœ¨æµè§ˆå™¨ä¸Šå‘ç°æ²¡å•¥å˜åŒ–ï¼Œä¸€ç‚¹åŠ¨é™éƒ½æ²¡æœ‰ã€‚è¿™å¾ˆå¯èƒ½æ˜¯githubä»“åº“çš„é—®é¢˜ï¼Œæ¨é€çš„åˆ†æ”¯æ˜¯masterï¼Œä½†æ˜¯github pageä¸Šçš„æ˜¯mainåˆ†æ”¯ã€‚è§£å†³åŠæ³•åˆ†ä¸¤æ­¥ï¼š1. è¿›å…¥repo-&gt;settings-&gt;pagesï¼Œå°†source branchä¿®æ”¹ä¸ºmaster 2. è¿›å…¥repo-&gt;settings-&gt;branchesï¼Œä¿®æ”¹é»˜è®¤åˆ†æ”¯ä¸ºmasterï¼ˆå…¶å®ç¬¬2æ­¥å¯ä»¥ä¸è¦ï¼‰</li><li>å¦‚æœä½ æœ‰è‡ªå·±çš„åŸŸåæƒ³ç»‘å®šï¼Œå‚è€ƒ<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="Github+Hexoæ­å»ºä¸ªäººç½‘ç«™è¯¦ç»†æ•™ç¨‹-çŸ¥ä¹é«˜èµ-å´æ¶¦">[1]</span></a></sup>ï¼Œè®°ä½ä¸€å®šæœ‰CNAMEæ–‡ä»¶ï¼Œå¦‚æœåªåœ¨repo-&gt;settings-&gt;pagesä¸­è®¾ç½®custom domainï¼Œ<code>hexo d</code>ä¼šåˆ·æ–°è®©å…¶æ— æ•ˆåŒ–</li><li>å«Œé»˜è®¤ä¸»é¢˜å¤ªä¸‘ï¼Œæˆ‘æ›´æ¢äº†fluidä¸»é¢˜<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="fluidä¸»é¢˜">[4]</span></a></sup>ï¼Œæƒ³æ·»åŠ è¯„è®ºåŠŸèƒ½çš„è¯ï¼Œå‚è€ƒ<sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote"><span class="hint--top hint--rounded" aria-label="utteranceè¯„è®ºç®¡ç†">[5]</span></a></sup>ï¼Œæƒ³<code>hexo new page XXX</code>æ–°å»ºé¡µï¼Œå¹¶åœ¨ä¸»é¡µä¸Šæ˜¾ç¤ºçš„è¯ï¼Œè¦åœ¨theme _configçš„menuä¸‹æ·»åŠ XXX</li></ul><h2 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h2><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a href="https://zhuanlan.zhihu.com/p/26625249">Github+Hexoæ­å»ºä¸ªäººç½‘ç«™è¯¦ç»†æ•™ç¨‹-çŸ¥ä¹é«˜èµ-å´æ¶¦</a><a href="#fnref:1" rev="footnote" class="footnote-backref"> â†©</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a href="https://stackoverflow.com/questions/68775869/support-for-password-authentication-was-removed-please-use-a-personal-access-to">github_token</a><a href="#fnref:2" rev="footnote" class="footnote-backref"> â†©</a></span></span></li><li><span id="fn:3" class="footnote-text"><span><a href="https://z.arlmy.me/posts/hexo/Hexo_DeployMeetsGFW/">å½“Hexoéƒ¨ç½²é‡åˆ°å¢™</a><a href="#fnref:3" rev="footnote" class="footnote-backref"> â†©</a></span></span></li><li><span id="fn:4" class="footnote-text"><span><a href="https://github.com/fluid-dev/hexo-theme-fluid">fluidä¸»é¢˜</a><a href="#fnref:4" rev="footnote" class="footnote-backref"> â†©</a></span></span></li><li><span id="fn:5" class="footnote-text"><span><a href="https://liaoyq.club/2020/04/03/hexo-fluid%E6%B7%BB%E5%8A%A0utterances%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD/">utteranceè¯„è®ºç®¡ç†</a><a href="#fnref:5" rev="footnote" class="footnote-backref"> â†©</a></span></span></li><li><span id="fn:6" class="footnote-text"><span><a href="https://segmentfault.com/q/1010000006864722">hexo_ssl_error</a><a href="#fnref:6" rev="footnote" class="footnote-backref"> â†©</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Others</category>
      
      <category>blog</category>
      
    </categories>
    
    
    <tags>
      
      <tag>blog</tag>
      
      <tag>pit</tag>
      
      <tag>github</tag>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
