

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  <meta name="description" content="Published by Google Research. 1. Main challenges in deep learning areas Sustainable Server-Side Scaling. deploying and letting inference run for over a long period of time could still turn out to be e">
<meta property="og:type" content="article">
<meta property="og:title" content="(Paper Reading) Efficient Deep Learning Survey A Survey on Making Deep Learning Models Smaller, Faster, and Better">
<meta property="og:url" content="http://example.com/2021/12/04/PR-Efficient-Deep-Learning-Survey/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Published by Google Research. 1. Main challenges in deep learning areas Sustainable Server-Side Scaling. deploying and letting inference run for over a long period of time could still turn out to be e">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://note.youdao.com/yws/api/personal/file/WEBcfe8440e5764dc0248ff1c33066dce7d?method=download&amp;shareKey=4407939a456a1e27e2b393d80cca4a52">
<meta property="og:image" content="https://note.youdao.com/yws/api/personal/file/WEB37a680e93db48a8953105f44a62c1327?method=download&amp;shareKey=659a4e53a58a749caf8e6403db38bf16">
<meta property="article:published_time" content="2021-12-04T05:16:37.000Z">
<meta property="article:modified_time" content="2021-12-04T06:15:10.508Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="paper">
<meta property="article:tag" content="google">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://note.youdao.com/yws/api/personal/file/WEBcfe8440e5764dc0248ff1c33066dce7d?method=download&amp;shareKey=4407939a456a1e27e2b393d80cca4a52">
  
  <title>(Paper Reading) Efficient Deep Learning Survey A Survey on Making Deep Learning Models Smaller, Faster, and Better - Hexo</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.12","typing":{"enable":true,"typeSpeed":100,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname"}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>MoonJian&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/daily/">
                <i class="iconfont icon-daily-fill"></i>
                每日一得
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/books">
                <i class="iconfont icon-books-fill"></i>
                阅读
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/movies">
                <i class="iconfont icon-movies-fill"></i>
                电影
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="(Paper Reading) Efficient Deep Learning Survey A Survey on Making Deep Learning Models Smaller, Faster, and Better">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2021-12-04 13:16" pubdate>
        December 4, 2021 pm
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      5k 字
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      16 分钟
    </span>
  

  
  
    
      <!-- 不蒜子统计文章PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">(Paper Reading) Efficient Deep Learning Survey A Survey on Making Deep Learning Models Smaller, Faster, and Better</h1>
            
            <div class="markdown-body">
              <p>Published by Google Research.</p>
<h2 id="1-Main-challenges-in-deep-learning-areas"><a href="#1-Main-challenges-in-deep-learning-areas" class="headerlink" title="1. Main challenges in deep learning areas"></a>1. Main challenges in deep learning areas</h2><ul>
<li><strong>Sustainable Server-Side Scaling</strong>. deploying and letting inference run for over a long period of time could still turn out to be expensive in terms of consumption of server-side RAM, CPU, etc.</li>
<li><strong>Enabling On-Device Deployment</strong>. Certain deep learning applications need to run real time on IoT and smart devices (where the model inference happens directly on the device), for a multitude of reasons (privacy, connectivity, responsiveness).</li>
<li><strong>Privacy &amp; Data Sensitivity</strong>. Being able to use as little data as possible for training is critical when the user-data might be sensitive.</li>
<li><strong>New Applications</strong>. Certain new applications offer new constraints (around model quality<br>or footprint) that existing off-the-shelf models might not be able to address.</li>
<li><strong>Explosion of Models</strong>. While a singular model might work well, training and/or deploying multiple models on the same infrastructure (colocation) for different applications might end up exhausting the available resources. (Multi-task learning?)</li>
</ul>
<p>Specifically, the common theme around the above challenges is <em>efficiency</em>, which can be categorized into two aspects:</p>
<ul>
<li>Inference Efficiency</li>
<li>Training Efficiency</li>
</ul>
<p>Our goal is to train and deploy pareto-optimal models with respect to model quality and its footprint.</p>
<h2 id="2-A-mental-model"><a href="#2-A-mental-model" class="headerlink" title="2. A mental model"></a>2. A mental model</h2><p><img src="https://note.youdao.com/yws/api/personal/file/WEBcfe8440e5764dc0248ff1c33066dce7d?method=download&amp;shareKey=4407939a456a1e27e2b393d80cca4a52" srcset="/img/loading.gif" lazyload alt="A mental model for thinking about algorithms, techniques, and tools related to efficiency in Deep Learning"></p>
<ul>
<li><strong>Compression Techniques</strong>. Pruning, quantization etc.</li>
<li><strong>Learning Techniques</strong>. Distillation etc.</li>
<li><strong>Automation</strong>. HPO, NAS etc.</li>
<li><strong>Efficient Architectures</strong>. Some fundamental blocks, such as conv, attention.</li>
<li><strong>Infrastructure</strong>. TF, Pytorch etc.</li>
</ul>
<h2 id="3-Landscape-of-Efficient-Deep-Learning"><a href="#3-Landscape-of-Efficient-Deep-Learning" class="headerlink" title="3. Landscape of Efficient Deep Learning"></a>3. Landscape of Efficient Deep Learning</h2><h3 id="3-1-Compression-Techniques"><a href="#3-1-Compression-Techniques" class="headerlink" title="3.1 Compression Techniques"></a>3.1 Compression Techniques</h3><p>In some cases if the model is over-parameterized, these techniques can improve model generalization.</p>
<ul>
<li><strong>Pruning</strong>, prefer structured pruning</li>
<li><strong>Quantization</strong>,  <ul>
<li><strong>Weight quantization</strong>, we can map the minimum weight value $(𝑥_{𝑚𝑖𝑛})$ in that matrix to 0, and the maximum value (𝑥𝑚𝑎𝑥 ) to $2^{b} − 1$ (where 𝑏 is the number of bits of precision, and 𝑏 &lt; 32). XNOR-Net, Binarized Neural Networks and others use 𝑏 = 1, and thus have weight matrices which just have two possible values 0 or 1, and the quantization function there is simply the $\sign(𝑥)$ function (assuming the weights are symmetrically distributed around 0). Binary quantization <strong>still need support from the underlying hardware</strong>. </li>
<li><strong>Activation quantization</strong>, This means all intermediate layer inputs and outputs are also in fixed-point, and there is no need to dequantize the weight matrices since they can be used directly along with the inputs. </li>
<li><font color=red><strong>Quantization-aware training (QAT)</strong></font>, post-training quantization leads to quality loss inference. <strong>Fake quantization</strong>, the training happens in floating-point but the forward-pass simulates the quantization behavior during inference.<br><img src="https://note.youdao.com/yws/api/personal/file/WEB37a680e93db48a8953105f44a62c1327?method=download&amp;shareKey=659a4e53a58a749caf8e6403db38bf16" srcset="/img/loading.gif" lazyload alt=""><br>QAT is good, but tools like TF Lite have made it easy to rely on post-training quantization. For performance reasons, it is best to consider the common operations that follow a typical layer such as Batch-Norm, Activation, etc. and ‘fold’ them in the quantization operations.</li>
</ul>
</li>
<li>Other Compression Techniques. There are other compression techniques like Low-Rank<br>Matrix Factorization, K-Means Clustering, Weight-Sharing etc. which are also actively being used for model compression and might be suitable for further compressing hotspots in a model.</li>
</ul>
<h3 id="3-2-Learning-Techniques"><a href="#3-2-Learning-Techniques" class="headerlink" title="3.2 Learning Techniques"></a>3.2 Learning Techniques</h3><ul>
<li><strong>Distillation</strong>, transfer ensembled models in weakly supervised learning to a smaller model (2006). Knowledge distillation, in my opinion, the large model provides informative relations among classes. Strategies for intermediate-layer distillation have also shown to be effective in the case of complex networks.</li>
<li><p><strong>Data augmentation</strong> (training efficiency), various transformations</p>
<ul>
<li><strong>label-invariant transformations</strong>, <em>e.g.</em>, flipping, cropping, rotations.</li>
<li><strong>Label-Mixing transformations</strong>, Mixup, The intuition is that the model should be<br>able to extract out features that are relevant for both the classes.</li>
<li><strong>Data-Dependent transformations</strong>, In this case, transformations are chosen such that they maximize the loss for that example [56], or are adversarially chosen so as to fool the classifier.</li>
<li><strong>Synthetic sampling</strong>, SMOTE, GAN</li>
<li><p><strong>Composition of transformations</strong>, combing above methods</p>
<p>Auto-Augment sounds practical…</p>
</li>
</ul>
</li>
<li><strong>Self-Supervised Learning</strong>, fine-tuning models pre-trained with Self-Supervised learning<br>are data-efficient (they converge faster, attain better quality for the same amount of labeled data when compared to training from scratch, etc.) Contrastive learning is effective. <strong>SSL provides a good pre-trained model for data-limited scenarios</strong>.</li>
</ul>
<h3 id="3-3-Automation"><a href="#3-3-Automation" class="headerlink" title="3.3 Automation"></a>3.3 Automation</h3><p>The trade-off is that these methods might require large computational resources, and hence have to be carefully applied.</p>
<ul>
<li><strong>Hyper-Parameter Optimization</strong>, Grid Search, Random Search (May not effective for high-dimensional space), Bayesian Optimization (it also makes the search sequential, though it is possible to run multiple trials in parallel, overall it will lead to some wasted trials.), Population based training (similar to evolutionary approaches), <strong>MAB algorithms</strong></li>
<li><strong>NAS</strong>, search space, search algorithm &amp; state, evaluation strategy. From single target accuracy to multi-goals, such as latency.</li>
</ul>
<h3 id="3-4-Efficient-Architectures"><a href="#3-4-Efficient-Architectures" class="headerlink" title="3.4 Efficient Architectures"></a>3.4 Efficient Architectures</h3><ul>
<li><strong>Depth-Separable Convolution</strong>, classical<br><img src=https://note.youdao.com/yws/api/personal/file/WEB94edd371460c9ac3912f34b0f9f85db3?method=download&shareKey=7715f1dfe158aeda2bcfd32dd843a0a3 style="zoom: 50%;" /></li>
<li><strong>Attention Mechanism &amp; Transformer Family</strong>, very hot!</li>
<li><strong>Random Projection Layers &amp; Models</strong>, The core-benefit of the projection operation when compared to embedding tables is 𝑂(𝑇 ) space required instead of 𝑂(𝑉 .𝑑) (𝑇 seeds required for 𝑇 hash functions). On the other hand, random-projection computation is 𝑂(𝑇 ) too v/s 𝑂(1) for embedding table lookup. Hence, the projection layer is clearly useful when model size is the primary focus of optimization. Reduce the memory, while increasing latency.</li>
</ul>
<h3 id="3-5-Infrastructure"><a href="#3-5-Infrastructure" class="headerlink" title="3.5 Infrastructure"></a>3.5 Infrastructure</h3><ul>
<li>TF Lite</li>
<li>PyTorch Mobile</li>
</ul>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Tech/">Tech</a>
                    
                      <a class="hover-with-bg" href="/categories/Tech/DL/">DL</a>
                    
                      <a class="hover-with-bg" href="/categories/Tech/DL/Compression/">Compression</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/paper/">paper</a>
                    
                      <a class="hover-with-bg" href="/tags/google/">google</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2021/12/22/PR-Domain-Generalization/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">(Paper Reading) 近期关于领域泛化文章的归纳整理</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2021/11/03/github-hexo-write-blog/">
                        <span class="hidden-mobile">Github + Hexo 搭建博客踩坑指南</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'MoonJian/commit-utterance');
      s.setAttribute('issue-term', 'title');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  
  <!-- 备案信息 -->
  <div class="beian">
    <span>
      <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
        苏ICP备19046742号
      </a>
    </span>
    
      
        <span>
          <a
            href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=19046742"
            rel="nofollow noopener"
            class="beian-police"
            target="_blank"
          >
            
            <span>苏公网安备19046742号</span>
          </a>
        </span>
      
    
  </div>


  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>



  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>















<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
